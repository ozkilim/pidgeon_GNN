{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QTA_EZGpYwlx"
      },
      "source": [
        "This notebook demonstrates our graph network inductive bias with a symbolic model extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lEKUuuYfTjP5"
      },
      "source": [
        "# Preamble and data generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IXpsg0LUb2sT"
      },
      "source": [
        "## Make sure to turn on the GPU via Edit-> Notebook settings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9imqRxveZl-J"
      },
      "outputs": [],
      "source": [
        "#Basic pre-reqs:\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = str(1) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9RTQhSJDbfLZ"
      },
      "source": [
        "## Download pre-reqs, and then code for simulations and model files:\n",
        "\n",
        "(Note: installing torch-geometric may take a long time.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "colab_type": "code",
        "id": "7XHuxuzNg0Ko",
        "outputId": "844f96c1-520b-40a0-d6b7-8930ed7eecae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: celluloid in /home/ozkilim/.local/lib/python3.8/site-packages (0.2.0)\n",
            "Requirement already satisfied: matplotlib in /home/ozkilim/.local/lib/python3.8/site-packages (from celluloid) (3.4.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ozkilim/.local/lib/python3.8/site-packages (from matplotlib->celluloid) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/ozkilim/.local/lib/python3.8/site-packages (from matplotlib->celluloid) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/ozkilim/.local/lib/python3.8/site-packages (from matplotlib->celluloid) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.16 in /home/ozkilim/.local/lib/python3.8/site-packages (from matplotlib->celluloid) (1.22.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->celluloid) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib->celluloid) (2.7.3)\n",
            "Requirement already satisfied: six in /home/ozkilim/.local/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->celluloid) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install celluloid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "colab_type": "code",
        "id": "DQy02pANbx2e",
        "outputId": "c81fa951-cb3a-44f1-bda6-de617363c013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu102.html\n",
            "Requirement already up-to-date: torch-scatter in /home/ozkilim/.local/lib/python3.8/site-packages (2.1.0+pt112cu102)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu102.html\n",
            "Requirement already up-to-date: torch-sparse in /home/ozkilim/.local/lib/python3.8/site-packages (0.6.15+pt112cu102)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /home/ozkilim/.local/lib/python3.8/site-packages (from torch-sparse) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.23.0,>=1.16.5 in /home/ozkilim/.local/lib/python3.8/site-packages (from scipy->torch-sparse) (1.22.4)\n",
            "Requirement already up-to-date: torch-geometric in /home/ozkilim/.local/lib/python3.8/site-packages (2.1.0.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /home/ozkilim/.local/lib/python3.8/site-packages (from torch-geometric) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /home/ozkilim/.local/lib/python3.8/site-packages (from torch-geometric) (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /home/ozkilim/.local/lib/python3.8/site-packages (from torch-geometric) (4.62.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing in /home/ozkilim/.local/lib/python3.8/site-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /home/ozkilim/.local/lib/python3.8/site-packages (from torch-geometric) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/lib/python3/dist-packages (from torch-geometric) (2.22.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /home/ozkilim/.local/lib/python3.8/site-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /home/ozkilim/.local/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/ozkilim/.local/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.0 in /home/ozkilim/.local/lib/python3.8/site-packages (from jinja2->torch-geometric) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "version_nums = torch.__version__.split('.')\n",
        "# Torch Geometric seems to always build for *.*.0 of torch :\n",
        "version_nums[-1] = '0' + version_nums[-1][1:]\n",
        "os.environ['TORCH'] = '.'.join(version_nums)\n",
        " \n",
        "!pip install --upgrade torch-scatter -f https://pytorch-geometric.com/whl/torch-${TORCH}.html && pip install --upgrade torch-sparse -f https://pytorch-geometric.com/whl/torch-${TORCH}.html && pip install --upgrade torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hVwSWJM-bl6Q"
      },
      "outputs": [],
      "source": [
        "import models\n",
        "import simulate\n",
        "# problem with compatability of packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kdgdkJwFZl-V"
      },
      "source": [
        "## Assert we have a GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "krahINlfZl-W",
        "outputId": "33d6e7e1-8fb5-47ef-c2fc-fc84316ffaff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.], device='cuda:0')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.ones(1).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zw9W7SB-Zl-i"
      },
      "source": [
        "## Create the simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "v8mC0I_lZl-j",
        "outputId": "dd430230-f1a9-4539-e612-467ad34f4e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on lj_n=6_dim=3_nt=1000_dt=0.01\n"
          ]
        }
      ],
      "source": [
        "# Number of simulations to run (it's fast, don't worry):\n",
        "ns = 95\n",
        "# Potential (see below for options)\n",
        "sim = 'lj'\n",
        "# Number of nodes\n",
        "n = 6\n",
        "# Dimension\n",
        "dim = 3\n",
        "# Number of time steps\n",
        "nt = 1000\n",
        "\n",
        "#Standard simulation sets:\n",
        "n_set = [4, 8]\n",
        "sim_sets = [\n",
        " {'sim': 'r1', 'dt': [5e-3], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'r2', 'dt': [1e-3], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'spring', 'dt': [1e-2], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'string', 'dt': [1e-2], 'nt': [1000], 'n': [30], 'dim': [2]},\n",
        " {'sim': 'charge', 'dt': [1e-3], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'superposition', 'dt': [1e-3], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'damped', 'dt': [2e-2], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'discontinuous', 'dt': [1e-2], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'lj', 'dt': [1e-2], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        "\n",
        "]\n",
        "\n",
        "#Select the hand-tuned dt value for a smooth simulation\n",
        "# (since scales are different in each potential):\n",
        "dt = [ss['dt'][0] for ss in sim_sets if ss['sim'] == sim][0]\n",
        "\n",
        "title = '{}_n={}_dim={}_nt={}_dt={}'.format(sim, n, dim, nt, dt)\n",
        "print('Running on', title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ARWJg6SbZl-n"
      },
      "source": [
        "## Generate simulation data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "38srsNZbZl-o"
      },
      "outputs": [],
      "source": [
        "from simulate import SimulationDataset\n",
        "s = SimulationDataset(sim, n=n, dim=dim, nt=nt//2, dt=dt)\n",
        "# Update this to your own dataset, or regenerate:\n",
        "\n",
        "base_str = './'\n",
        "data_str = title\n",
        "s.simulate(ns)\n",
        "# inspect the structure here and load up the pidgeon flight data..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "_iWH9BfUZl-r",
        "outputId": "4f70a812-4f4f-42bb-c066-23e92fb738c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'jaxlib.xla_extension.DeviceArray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(s.data))\n",
        "# 10000 simulations, 500 frames each, 4 particles, 6 values for each particle?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8sCvhjgVpWIx"
      },
      "source": [
        "### Let's visualize an example simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "y5hFgzapZl-u",
        "outputId": "49a5e715-e36d-473c-c77d-e5ccafbac24b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from celluloid import Camera\n",
        "\n",
        "s.plot(5, animate=True, plot_size=False) #save this for readme\n",
        "# camera.animate().save('multiple_animations_with_comparison.mp4')\n",
        "fig = plt.gcf()\n",
        "camera = Camera(fig)\n",
        "\n",
        "animation = camera.animate()\n",
        "animation.save('../animations/lj.gif',fps=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1PRxdcqSZl-z"
      },
      "source": [
        "## We'll train on the accelerations, so let's generate the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZzHxTkcKZl-0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(95, 500, 6, 3)\n",
            "<class 'jaxlib.xla_extension.DeviceArray'>\n"
          ]
        }
      ],
      "source": [
        "accel_data = s.get_acceleration()\n",
        "print(accel_data.shape)\n",
        "print(type(accel_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j2j1M4coZl-3"
      },
      "outputs": [],
      "source": [
        "# try with our own real data now...\n",
        "\n",
        "# accel_data = np.load(\"../vicek_sim/flight_acells.npy\").astype(np.float32)\n",
        "# s.data = np.load(\"../vicek_sim/flight_feats.npy\").astype(np.float32)\n",
        "\n",
        "X = torch.from_numpy(np.concatenate([s.data[:, i] for i in range(0, s.data.shape[1], 5)]))\n",
        "y = torch.from_numpy(np.concatenate([accel_data[:, i] for i in range(0, s.data.shape[1], 5)]))\n",
        "\n",
        "data = s.data #important to keep!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7e8JdFUWZl-5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "skQDNVroZl-8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([9500, 6, 8])\n",
            "torch.Size([9500, 6, 3])\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "# inspect the form of the data here! 6 features for train and 2 for test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fz05x2HLT5Kg"
      },
      "source": [
        "# Set up the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XWcn4EEFZl-_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "from torch_geometric.nn import MetaLayer, MessagePassing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "E-uVcXRcZl_D"
      },
      "outputs": [],
      "source": [
        "from models import OGN, varOGN, make_packer, make_unpacker, get_edge_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kBtdfcvgZl_F"
      },
      "source": [
        "## Use the L1 regularization model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PyKcc5zbZl_H"
      },
      "outputs": [],
      "source": [
        "aggr = 'add'\n",
        "hidden = 500 #was 300\n",
        "\n",
        "test = '_l1_' #turn off regulerisation to try to overfit at the start...\n",
        "# test = _l1_\n",
        "#This test applies an explicit bottleneck:\n",
        "\n",
        "msg_dim = 100 \n",
        "n_f = data.shape[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oDiU99YHZl_K"
      },
      "source": [
        "L1 loss: we simply add the loss to the batch number. I.e., * 32 for batch size 32.\n",
        "\n",
        "KL loss: model the messages as a distribution with the prior a Gaussian. The means add in the final Gaussian. \n",
        "Recall in the D_KL(p||q), the prior is q.  Then, for sigma_q = 1, mu_q = 0, we have ($p=1$):\n",
        "\n",
        "$$D_{KL}(p||q) = \\frac{\\sigma_p^2 + \\mu_p^2}{2} -\\log({\\sigma_p}) - \\frac{1}{2}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gTHRRgTuZl_K"
      },
      "source": [
        "## We use a custom data loader for the graphs for fast training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oL-1skODZl_L"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JbkHAAPzZl_N"
      },
      "outputs": [],
      "source": [
        "from models import get_edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FOI75DW0Zl_Q"
      },
      "outputs": [],
      "source": [
        "edge_index = get_edge_index(n, sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g46wRgIWZl_S"
      },
      "source": [
        "## Initiate the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1bs7l6xYZl_T"
      },
      "outputs": [],
      "source": [
        "if test == '_kl_':\n",
        "    ogn = varOGN(n_f, msg_dim, dim, dt=0.1, hidden=hidden, edge_index=get_edge_index(n, sim), aggr=aggr).cuda()\n",
        "else:\n",
        "    ogn = OGN(n_f, msg_dim, dim, dt=0.1, hidden=hidden, edge_index=get_edge_index(n, sim), aggr=aggr).cuda()\n",
        "\n",
        "messages_over_time = []\n",
        "ogn = ogn.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i1SJ012hZl_V"
      },
      "source": [
        "### Let's test it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "eSea_DJ-Zl_W",
        "outputId": "65989f6e-0ae4-4590-dd9d-a39291375619"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0360, 0.1525, 0.1247],\n",
              "         [0.0040, 0.0555, 0.0116],\n",
              "         [0.0077, 0.0832, 0.0165],\n",
              "         [0.0115, 0.0593, 0.0115],\n",
              "         [0.0105, 0.0617, 0.0222],\n",
              "         [0.0039, 0.0759, 0.0237]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
              " torch.Size([6, 3]),\n",
              " torch.Size([6, 3]),\n",
              " tensor(104.1945, device='cuda:0', grad_fn=<SumBackward0>))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_q = Data(\n",
        "    x=X_train[0].cuda(),\n",
        "    edge_index=edge_index.cuda(),\n",
        "    y=y_train[0].cuda())\n",
        "\n",
        "ogn(_q.x, _q.edge_index), ogn.just_derivative(_q).shape, _q.y.shape, ogn.loss(_q), "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RszfVgfhZl_a"
      },
      "source": [
        "# Set up training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WK5_u9F7UttT"
      },
      "source": [
        "## Organize into data loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8JyKnPWnZl_b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ozkilim/.local/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "batch = int(64 * (4 / n)**2)\n",
        "trainloader = DataLoader(\n",
        "    [Data(\n",
        "        Variable(X_train[i]),\n",
        "        edge_index=edge_index,\n",
        "        y=Variable(y_train[i])) for i in range(len(y_train))],\n",
        "    batch_size=batch,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "testloader = DataLoader(\n",
        "    [Data(\n",
        "        X_test[i],\n",
        "        edge_index=edge_index,\n",
        "        y=y_test[i]) for i in range(len(y_test))],\n",
        "    batch_size=1024,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yyduWbndZl_e"
      },
      "source": [
        "## We'll use OneCycleLR for fast training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3dXp3rkuZl_f"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hSqOrC1WZl_l"
      },
      "source": [
        "## Create the loss function\n",
        "\n",
        "This holds definition of our L1 and KL regularizations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U6EHSHiOZl_m"
      },
      "outputs": [],
      "source": [
        "def new_loss(self, g, augment=True, square=False):\n",
        "    if square:\n",
        "        return torch.sum((g.y - self.just_derivative(g, augment=augment))**2)\n",
        "    else:\n",
        "        base_loss = torch.sum(torch.abs(g.y - self.just_derivative(g, augment=augment)))\n",
        "        if test in ['_l1_', '_kl_']:\n",
        "            s1 = g.x[self.edge_index[0]]\n",
        "            s2 = g.x[self.edge_index[1]]\n",
        "            if test == '_l1_':\n",
        "                m12 = self.message(s1, s2)\n",
        "                regularization = 1e-2\n",
        "                #Want one loss value per row of g.y:\n",
        "                normalized_l05 = torch.sum(torch.abs(m12))\n",
        "                return base_loss, regularization * batch * normalized_l05 / n**2 * n\n",
        "            elif test == '_kl_':\n",
        "                regularization = 1\n",
        "                #Want one loss value per row of g.y:\n",
        "                tmp = torch.cat([s1, s2], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
        "                raw_msg = self.msg_fnc(tmp)\n",
        "                mu = raw_msg[:, 0::2]\n",
        "                logvar = raw_msg[:, 1::2]\n",
        "                full_kl = torch.sum(torch.exp(logvar) + mu**2 - logvar)/2.0\n",
        "                return base_loss, regularization * batch * full_kl / n**2 * n\n",
        "        return base_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w12Qg4t_em8w"
      },
      "source": [
        "## Set up optimizer and training parameters:\n",
        "\n",
        "**Use 200 epochs for full version; can use fewer for test.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "y_KbxGDEZl_p",
        "outputId": "1c7f38d0-c33e-4c2b-ee92-480b36eed172"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11428"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "init_lr = 1e-3\n",
        "\n",
        "opt = torch.optim.Adam(ogn.parameters(), lr=init_lr, weight_decay=1e-8)\n",
        "\n",
        "total_epochs = 50\n",
        "# total_epochs = 30\n",
        "\n",
        "batch_per_epoch = int(1000*10 / (batch/32.0))\n",
        "\n",
        "sched = OneCycleLR(opt, max_lr=init_lr,\n",
        "                   steps_per_epoch=batch_per_epoch,#len(trainloader),\n",
        "                   epochs=total_epochs, final_div_factor=1e5)\n",
        "\n",
        "batch_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4AyhMeZ7Zl_r"
      },
      "outputs": [],
      "source": [
        "epoch = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "s6Q_XHHOZl_v"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y4EzD79nU8DO"
      },
      "source": [
        "## Organize the recording of messages over time\n",
        "\n",
        "This is for fitting the forces, and extracting laws:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "J2jTb8r-Zl_z"
      },
      "outputs": [],
      "source": [
        "import numpy as onp\n",
        "onp.random.seed(0)\n",
        "test_idxes = onp.random.randint(0, len(X_test), 1000)\n",
        "\n",
        "#Record messages over test dataset here:\n",
        "newtestloader = DataLoader(\n",
        "    [Data(\n",
        "        X_test[i],\n",
        "        edge_index=edge_index,\n",
        "        y=y_test[i]) for i in test_idxes],\n",
        "    batch_size=len(X_test),\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uxtqu4E4erXd"
      },
      "source": [
        "### Function to record messages from model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0k9hfsslZl_2"
      },
      "outputs": [],
      "source": [
        "import numpy as onp\n",
        "import pandas as pd\n",
        "\n",
        "def get_messages(ogn):\n",
        "\n",
        "    def get_message_info(tmp):\n",
        "        ogn.cpu()\n",
        "\n",
        "        s1 = tmp.x[tmp.edge_index[0]]\n",
        "        s2 = tmp.x[tmp.edge_index[1]]\n",
        "        tmp = torch.cat([s1, s2], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
        "        if test == '_kl_':\n",
        "            raw_msg = ogn.msg_fnc(tmp)\n",
        "            mu = raw_msg[:, 0::2]\n",
        "            logvar = raw_msg[:, 1::2]\n",
        "\n",
        "            m12 = mu\n",
        "        else:\n",
        "            m12 = ogn.msg_fnc(tmp)\n",
        "\n",
        "        all_messages = torch.cat((\n",
        "            s1,\n",
        "            s2,\n",
        "            m12), dim=1)\n",
        "        if dim == 2:\n",
        "            columns = [elem%(k) for k in range(1, 3) for elem in 'x%d y%d vx%d vy%d q%d m%d'.split(' ')]\n",
        "            columns += ['e%d'%(k,) for k in range(msg_dim)]\n",
        "        elif dim == 3:\n",
        "            columns = [elem%(k) for k in range(1, 3) for elem in 'x%d y%d z%d vx%d vy%d vz%d q%d m%d'.split(' ')]\n",
        "            columns += ['e%d'%(k,) for k in range(msg_dim)]\n",
        "\n",
        "\n",
        "        return pd.DataFrame(\n",
        "            data=all_messages.cpu().detach().numpy(),\n",
        "            columns=columns\n",
        "        )\n",
        "\n",
        "    msg_info = []\n",
        "    for i, g in enumerate(newtestloader):\n",
        "        msg_info.append(get_message_info(g))\n",
        "\n",
        "    msg_info = pd.concat(msg_info)\n",
        "    msg_info['dx'] = msg_info.x1 - msg_info.x2\n",
        "    msg_info['dy'] = msg_info.y1 - msg_info.y2\n",
        "    if dim == 2:\n",
        "        msg_info['r'] = np.sqrt(\n",
        "            (msg_info.dx)**2 + (msg_info.dy)**2\n",
        "        )\n",
        "    elif dim == 3:\n",
        "        msg_info['dz'] = msg_info.z1 - msg_info.z2\n",
        "        msg_info['r'] = np.sqrt(\n",
        "            (msg_info.dx)**2 + (msg_info.dy)**2 + (msg_info.dz)**2\n",
        "        )\n",
        "    \n",
        "    return msg_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RsLYGJX8Zl_5"
      },
      "outputs": [],
      "source": [
        "recorded_models = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lGJSTkWOZl_7"
      },
      "source": [
        "# Train the model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x-M9IDuiVrot"
      },
      "source": [
        "## Training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "colab_type": "code",
        "id": "NHxCTt_tZl_7",
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "outputId": "b7f9e679-f490-4f39-92cb-61d7e6563666"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2563744.854565529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 2/50 [03:02<1:13:00, 91.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2563732.2120058388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 3/50 [04:33<1:11:22, 91.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2560722.196257419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 4/50 [06:04<1:09:47, 91.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2561907.6946718376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 5/50 [07:35<1:08:19, 91.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2510997.113923669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 6/50 [09:07<1:06:52, 91.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2512854.6877388665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 6/50 [10:31<1:17:09, 105.22s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1036631/146749042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mginput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mginput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_l1_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_kl_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mogn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mginput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mginput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_1036631/2851234483.py\u001b[0m in \u001b[0;36mnew_loss\u001b[0;34m(self, g, augment, square)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_l1_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_kl_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'_l1_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mm12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in tqdm(range(epoch, total_epochs)):\n",
        "    ogn.cuda()\n",
        "    total_loss = 0.0\n",
        "    i = 0\n",
        "    num_items = 0\n",
        "    while i < batch_per_epoch:\n",
        "        for ginput in trainloader:\n",
        "            if i >= batch_per_epoch:\n",
        "                break\n",
        "            opt.zero_grad()\n",
        "            ginput.x = ginput.x.cuda()\n",
        "            ginput.y = ginput.y.cuda()\n",
        "            ginput.edge_index = ginput.edge_index.cuda()\n",
        "            ginput.batch = ginput.batch.cuda()\n",
        "            if test in ['_l1_', '_kl_']:\n",
        "                loss, reg = new_loss(ogn, ginput, square=False)\n",
        "                ((loss + reg)/int(ginput.batch[-1]+1)).backward()\n",
        "            else:\n",
        "                loss = ogn.loss(ginput, square=False)\n",
        "                (loss/int(ginput.batch[-1]+1)).backward()\n",
        "            opt.step()\n",
        "            sched.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            i += 1\n",
        "            num_items += int(ginput.batch[-1]+1)\n",
        "\n",
        "    cur_loss = total_loss/num_items\n",
        "    print(cur_loss) #can we view the training loss to check its working?... looks thike this is the train loss?...\n",
        "    cur_msgs = get_messages(ogn)\n",
        "    cur_msgs['epoch'] = epoch\n",
        "    cur_msgs['loss'] = cur_loss\n",
        "    messages_over_time.append(cur_msgs)\n",
        "    \n",
        "    ogn.cpu()\n",
        "    from copy import deepcopy as copy\n",
        "    recorded_models.append(ogn.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NZx6ngcZjeif"
      },
      "source": [
        "Normally you should run all the way to 200 epochs (set this as a parameter so that OneCycleLR is set correctly). This loop was cut off early to quickly test this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YAqyXbr9dpKE"
      },
      "source": [
        "## Save and Load models here to prevent re-training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7eQ9087RZmAA"
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "pkl.dump(messages_over_time,\n",
        "    open('../data/messages_over_time_lj.pkl', 'wb'))\n",
        "messages_over_time = pkl.load(open('../data/messages_over_time_lj.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "i8i0qy2tZmAD"
      },
      "outputs": [],
      "source": [
        "pkl.dump(recorded_models,\n",
        "    open('../data/models_over_time_lj.pkl', 'wb'))\n",
        "\n",
        "recorded_models = pkl.load(open('../data/models_over_time_lj.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iC7pYpZnVwFG"
      },
      "source": [
        "# Analyze trained model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c3R-CJtQZmAJ"
      },
      "source": [
        "## Plot a comparison of the force components with the messages:\n",
        "\n",
        "### (Or plot the rotation or sparsity - turn these on and off with flags:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "12_ldordZmAP"
      },
      "outputs": [],
      "source": [
        "from celluloid import Camera\n",
        "from copy import deepcopy as copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMVQTRFMV2ZL"
      },
      "source": [
        "Options include:\n",
        "\n",
        "- plot_force_components: the scatter plots of true force versus message\n",
        "- plot_sparsity: the grayscale animation of the message components over time\n",
        "- plot_rotation: plot the vectors showing how the messages are rotations of the true vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "x4slGzWtZmAS",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "d82a2e68-5f63-4673-8748-9042974c134f"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Only turn on one of these:\n",
        "plot_force_components = True\n",
        "plot_sparsity = False\n",
        "plot_rotation = False\n",
        "if plot_force_components:\n",
        "    fig, ax = plt.subplots(1, dim, figsize=(4*dim, 4))\n",
        "if plot_sparsity or plot_rotation:\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "cam = Camera(fig)\n",
        "\n",
        "\n",
        "last_alpha_x1 = 0.0\n",
        "last_alpha_y1 = 0.0\n",
        "t = lambda _: _#tqdm\n",
        "for i in t(range(0, len(messages_over_time), 1)):\n",
        "    msgs = copy(messages_over_time[i])\n",
        "\n",
        "    msgs['bd'] = msgs.r + 1e-2\n",
        "\n",
        "    try:\n",
        "        msg_columns = ['e%d'%(k) for k in range(1, msg_dim+1)]\n",
        "        msg_array = np.array(msgs[msg_columns])\n",
        "    except:\n",
        "        msg_columns = ['e%d'%(k) for k in range(msg_dim)]\n",
        "        msg_array = np.array(msgs[msg_columns])\n",
        "\n",
        "    msg_importance = msg_array.std(axis=0)\n",
        "    most_important = np.argsort(msg_importance)[-dim:]\n",
        "    msgs_to_compare = msg_array[:, most_important]\n",
        "    msgs_to_compare = (msgs_to_compare - np.average(msgs_to_compare, axis=0)) / np.std(msgs_to_compare, axis=0)\n",
        "\n",
        "    if plot_sparsity:\n",
        "        ax.pcolormesh(msg_importance[np.argsort(msg_importance)[::-1][None, :15]], cmap='gray_r', edgecolors='k')\n",
        "        # plt.colorbar()\n",
        "        plt.axis('off')\n",
        "        plt.grid(True)\n",
        "        ax.set_aspect('equal')\n",
        "        plt.text(15.5, 0.5, '...', fontsize=30)\n",
        "        # fig.suptitle(title + test + 'mse=%.3e'%(min_result.fun/len(msgs),))\n",
        "        plt.tight_layout()\n",
        "    \n",
        "    if plot_force_components or plot_rotation:\n",
        "        pos_cols = ['dx', 'dy']\n",
        "        if dim == 3:\n",
        "            pos_cols.append('dz')\n",
        "\n",
        "        if sim != 'spring':\n",
        "            raise NotImplementedError(\"The current force function is for a spring. You will need to change the force function below to that expected by your simulation.\")\n",
        "        force_fnc = lambda msg: -(msg.bd - 1)[:, None] * np.array(msg[pos_cols]) / msg.bd[:, None]\n",
        "\n",
        "        expected_forces = force_fnc(msgs)\n",
        "\n",
        "        def percentile_sum(x):\n",
        "            x = x.ravel()\n",
        "            bot = x.min()\n",
        "            top = np.percentile(x, 90)\n",
        "            msk = (x>=bot) & (x<=top)\n",
        "            frac_good = (msk).sum()/len(x)\n",
        "            return x[msk].sum()/frac_good\n",
        "\n",
        "        from scipy.optimize import minimize\n",
        "\n",
        "        def linear_transformation_2d(alpha):\n",
        "\n",
        "            lincomb1 = (alpha[0] * expected_forces[:, 0] + alpha[1] * expected_forces[:, 1]) + alpha[2]\n",
        "            lincomb2 = (alpha[3] * expected_forces[:, 0] + alpha[4] * expected_forces[:, 1]) + alpha[5]\n",
        "\n",
        "            score = (\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 0] - lincomb1)) +\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 1] - lincomb2))\n",
        "            )/2.0\n",
        "\n",
        "            return score\n",
        "\n",
        "        def out_linear_transformation_2d(alpha):\n",
        "            lincomb1 = (alpha[0] * expected_forces[:, 0] + alpha[1] * expected_forces[:, 1]) + alpha[2]\n",
        "            lincomb2 = (alpha[3] * expected_forces[:, 0] + alpha[4] * expected_forces[:, 1]) + alpha[5]\n",
        "\n",
        "            return lincomb1, lincomb2\n",
        "\n",
        "        def linear_transformation_3d(alpha):\n",
        "\n",
        "            lincomb1 = (alpha[0] * expected_forces[:, 0] + alpha[1] * expected_forces[:, 1] + alpha[2] * expected_forces[:, 2]) + alpha[3]\n",
        "            lincomb2 = (alpha[0+4] * expected_forces[:, 0] + alpha[1+4] * expected_forces[:, 1] + alpha[2+4] * expected_forces[:, 2]) + alpha[3+4]\n",
        "            lincomb3 = (alpha[0+8] * expected_forces[:, 0] + alpha[1+8] * expected_forces[:, 1] + alpha[2+8] * expected_forces[:, 2]) + alpha[3+8]\n",
        "\n",
        "            score = (\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 0] - lincomb1)) +\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 1] - lincomb2)) +\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 2] - lincomb3))\n",
        "            )/3.0\n",
        "\n",
        "            return score\n",
        "\n",
        "        def out_linear_transformation_3d(alpha):\n",
        "\n",
        "            lincomb1 = (alpha[0] * expected_forces[:, 0] + alpha[1] * expected_forces[:, 1] + alpha[2] * expected_forces[:, 2]) + alpha[3]\n",
        "            lincomb2 = (alpha[0+4] * expected_forces[:, 0] + alpha[1+4] * expected_forces[:, 1] + alpha[2+4] * expected_forces[:, 2]) + alpha[3+4]\n",
        "            lincomb3 = (alpha[0+8] * expected_forces[:, 0] + alpha[1+8] * expected_forces[:, 1] + alpha[2+8] * expected_forces[:, 2]) + alpha[3+8]\n",
        "\n",
        "            return lincomb1, lincomb2, lincomb3\n",
        "\n",
        "        if dim == 2:\n",
        "            min_result = minimize(linear_transformation_2d, np.ones(dim**2 + dim), method='Powell')\n",
        "        if dim == 3:\n",
        "            min_result = minimize(linear_transformation_3d, np.ones(dim**2 + dim), method='Powell')\n",
        "        print(title, test, 'gets', min_result.fun/len(msgs))\n",
        "\n",
        "        if plot_rotation:\n",
        "            q = min_result.x\n",
        "            alphax1, alphay1, offset1 = q[:3]\n",
        "            alphax2, alphay2, offset2 = q[3:]\n",
        "            \n",
        "            s1 = alphax1**2 + alphay1**2\n",
        "            s2 = alphax2**2 + alphay2**2\n",
        "            \n",
        "            if (\n",
        "                    (alphax2 - last_alpha_x1)**2\n",
        "                    + (alphay2 - last_alpha_y1)**2  <\n",
        "                   (alphax1 - last_alpha_x1)**2\n",
        "                    + (alphay1 - last_alpha_y1)**2):\n",
        "                \n",
        "                alphax1, alphay1, offset1 = q[3:]\n",
        "                alphax2, alphay2, offset2 = q[:3]\n",
        "                \n",
        "            last_alpha_x1 = alphax1\n",
        "            last_alpha_y1 = alphay1\n",
        "            s1 = alphax1**2 + alphay1**2\n",
        "            s2 = alphax2**2 + alphay2**2\n",
        "            alphax1 /= s1**0.5 * 2\n",
        "            alphay1 /= s1**0.5 * 2\n",
        "            alphax2 /= s2**0.5 * 2\n",
        "            alphay2 /= s2**0.5 * 2\n",
        "            \n",
        "            ax.arrow(0.5, 0.5, alphax1, alphay1, color='k', head_width=0.05, length_includes_head=True)\n",
        "            ax.arrow(0.5, 0.5, alphax2, alphay2, color='k', head_width=0.05, length_includes_head=True)\n",
        "            ax.axis('off')\n",
        "        \n",
        "        if plot_force_components:\n",
        "            for i in range(dim):\n",
        "                if dim == 3:\n",
        "                    px = out_linear_transformation_3d(min_result.x)[i]\n",
        "                else:\n",
        "                    px = out_linear_transformation_2d(min_result.x)[i]\n",
        "\n",
        "                py = msgs_to_compare[:, i]\n",
        "                ax[i].scatter(px, py,\n",
        "                              alpha=0.1, s=0.1, color='k')\n",
        "                ax[i].set_xlabel('Linear combination of forces')\n",
        "                ax[i].set_ylabel('Message Element %d'%(i+1))\n",
        "\n",
        "                xlim = np.array([np.percentile(px, q) for q in [10, 90]])\n",
        "                ylim = np.array([np.percentile(py, q) for q in [10, 90]])\n",
        "                xlim[0], xlim[1] = xlim[0] - (xlim[1] - xlim[0])*0.05, xlim[1] + (xlim[1] - xlim[0])*0.05\n",
        "                ylim[0], ylim[1] = ylim[0] - (ylim[1] - ylim[0])*0.05, ylim[1] + (ylim[1] - ylim[0])*0.05\n",
        "\n",
        "                ax[i].set_xlim(xlim)\n",
        "                ax[i].set_ylim(ylim)\n",
        "                \n",
        "        plt.tight_layout()\n",
        "    \n",
        "    cam.snap()\n",
        "\n",
        "ani = cam.animate()\n",
        "    \n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "huBwFGpGZmAa"
      },
      "source": [
        "## Plot some predicted versus true trajectories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MCJkRYfNZmAb"
      },
      "outputs": [],
      "source": [
        "from simulate import make_transparent_color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "os18WuvhZmAc"
      },
      "outputs": [],
      "source": [
        "from scipy.integrate import odeint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "colab_type": "code",
        "id": "-9fKkNNeZmAi",
        "outputId": "d1cbb00f-484f-4896-9c34-84039ce3df61"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "camera = Camera(fig)\n",
        "\n",
        "for current_model in [-1] + [1, 34, 67, 100, 133, 166, 199]:\n",
        "    i = 0 #which video to use. 5 is interesting\n",
        "    if current_model > len(recorded_models):\n",
        "        continue\n",
        "    \n",
        "    #Truth:\n",
        "    cutoff_time = 300\n",
        "    times = onp.array(s.times)[:cutoff_time]\n",
        "\n",
        "    print(data.shape) # this is not our data!\n",
        "\n",
        "    x_times = onp.array(data[i, :cutoff_time])\n",
        "    length_of_tail = 75\n",
        "\n",
        "    #Learned:\n",
        "    e = edge_index.cuda()\n",
        "    ogn.cpu()\n",
        "    # if current_model > -1:\n",
        "    #     print(\"using model\")\n",
        "    ogn.load_state_dict(recorded_models[current_model])\n",
        "    \n",
        "    # else:\n",
        "    #     # Random model!\n",
        "    # ogn = OGN(n_f, msg_dim, dim, dt=0.1, hidden=hidden, edge_index=get_edge_index(n, sim), aggr=aggr).cuda()\n",
        "    ogn.cuda()\n",
        "    \n",
        "    def odefunc(y, t=None):\n",
        "        # print(y.shape) 48\n",
        "        y = y.reshape(6, 8).astype(np.float32)\n",
        "        cur = Data(\n",
        "            x=torch.from_numpy(y).cuda(),\n",
        "            edge_index=e\n",
        "        )\n",
        "        dx = y[:, 3:6] #actually not 2:4 its \n",
        "        # dv = y[:, 6:6]\n",
        "        dv = ogn.just_derivative(cur).cpu().detach().numpy()\n",
        "        # print(dv) # this output is always the same! does not change as a function of the state of the system..  try random\n",
        "        # dother = np.zeros_like(dx)\n",
        "        dother = np.zeros((6,2))\n",
        "        return np.concatenate((dx, dv, dother), axis=1).ravel()\n",
        "\n",
        "    # Make predictions and back into simulations\n",
        "    datai = odeint(odefunc, (onp.asarray(x_times[0]).ravel()), times).reshape(-1, 6, 8)\n",
        "    x_times2 = onp.array(datai)\n",
        "\n",
        "    d_idx = 10\n",
        "    for t_idx in range(d_idx, cutoff_time, d_idx):\n",
        "        start = max([0, t_idx-length_of_tail])\n",
        "        ctimes = times[start:t_idx]\n",
        "        cx_times = x_times[start:t_idx]\n",
        "        cx_times2 = x_times2[start:t_idx]\n",
        "        for j in range(n):\n",
        "            rgba = make_transparent_color(len(ctimes), j/n)\n",
        "            ax[0].scatter(cx_times[:, j, 0], cx_times[:, j, 1], color=rgba)\n",
        "            ax[1].scatter(cx_times2[:, j, 0], cx_times2[:, j, 1], color=rgba)\n",
        "            black_rgba = rgba\n",
        "            black_rgba[:, :3] = 0.75\n",
        "            ax[1].scatter(cx_times[:, j, 0], cx_times[:, j, 1], color=black_rgba, zorder=-1)\n",
        "\n",
        "        # for k in range(2):\n",
        "        #     ax[k].set_xlim(-1, 3)\n",
        "        #     ax[k].set_ylim(-3, 1)\n",
        "        plt.tight_layout()\n",
        "        camera.snap()\n",
        "    # break\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(camera.animate().to_jshtml())\n",
        "\n",
        "animation = camera.animate()\n",
        "animation.save('../animations/predictiosns_lj.gif',fps=10)\n",
        "# plot some stats of acceleraions for all the videos... to see the distrribtution we are learning..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hLJGeV4IXtxc"
      },
      "source": [
        "# Symbolic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-LHESeG4XquY"
      },
      "source": [
        "Extract the force laws with the following procedure:\n",
        "- The data in `messages_over_time` correspond to inputs to, and features of, $\\phi^e$, recorded during each training epoch.\n",
        "- Select the last element of this list.\n",
        "- Find the most significant message feature. Each message feature corresponds to 'e1', 'e2', etc. Calculate the one with the largest standard deviation.\n",
        "\n",
        "Train [PySR](https://github.com/MilesCranmer/PySR) to fit this relationship.\n",
        "Thus, we have extracted a force law from the graph network without priors on the functional form.\n",
        "\n",
        "This is the same technique we used to extract the unknown dark matter overdensity equation from the Quijote simulations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hwgQjt-_ic5k"
      },
      "source": [
        "## Here's the best message, which we will study:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "G1rhnbq-XvG5"
      },
      "outputs": [],
      "source": [
        "best_message = np.argmax([np.std(messages_over_time[-1]['e%d'%(i,)]) for i in range(100)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EAhN3sdzif0p"
      },
      "source": [
        "## Here's a pandas dataframe of the message data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "colab_type": "code",
        "id": "-2lNO8p1h2pt",
        "outputId": "05648bd9-81b3-4d5c-a4c3-d453707b9751"
      },
      "outputs": [],
      "source": [
        "messages_over_time[-1][['e%d'%(best_message,), 'dx', 'dy', 'r', 'm1', 'm2']] # adjust this to fit our form. first train on fullscale dataset....."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Ipu1gX0ijYv"
      },
      "source": [
        "## Now we just fit e4 as a function of dx, dy, r, m1, and m2, inside [PySR](https://github.com/MilesCranmer/PySR)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "lEKUuuYfTjP5",
        "IXpsg0LUb2sT",
        "9RTQhSJDbfLZ",
        "kdgdkJwFZl-V",
        "Zw9W7SB-Zl-i",
        "ARWJg6SbZl-n",
        "1PRxdcqSZl-z",
        "Fz05x2HLT5Kg",
        "kBtdfcvgZl_F",
        "gTHRRgTuZl_K",
        "g46wRgIWZl_S",
        "RszfVgfhZl_a",
        "WK5_u9F7UttT",
        "yyduWbndZl_e",
        "hSqOrC1WZl_l",
        "w12Qg4t_em8w",
        "Y4EzD79nU8DO",
        "Uxtqu4E4erXd"
      ],
      "name": "GN_Demo",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
